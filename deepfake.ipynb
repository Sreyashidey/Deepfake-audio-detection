{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3842332,"sourceType":"datasetVersion","datasetId":2286778}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torchaudio\nimport librosa\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, roc_curve\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:29:39.498670Z","iopub.execute_input":"2025-04-05T05:29:39.498916Z","iopub.status.idle":"2025-04-05T05:29:45.694538Z","shell.execute_reply.started":"2025-04-05T05:29:39.498891Z","shell.execute_reply":"2025-04-05T05:29:45.693363Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class ASVspoofDataset(Dataset):\n    def __init__(self, data_dir, label_file, sample_rate=16000):\n        self.data_dir = data_dir\n        self.sample_rate = sample_rate\n        self.files, self.labels = self.load_labels(label_file)\n\n    def load_labels(self, label_file):\n        files = []\n        labels = {}\n        with open(label_file, 'r') as f:\n            for line in f.readlines():\n                parts = line.strip().split()\n                filename = parts[1]  # Filename\n                label = 1 if parts[-1] == 'spoof' else 0\n                files.append(filename)\n                labels[filename] = label\n        return files, labels\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        filename = self.files[idx]\n        label = self.labels[filename]\n        filepath = os.path.join(self.data_dir, filename + \".flac\")  # .flac extension\n        \n        waveform, sr = torchaudio.load(filepath)\n        if sr != self.sample_rate:\n            waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.sample_rate)(waveform)\n        \n        return waveform, torch.tensor(label, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:30:01.539219Z","iopub.execute_input":"2025-04-05T05:30:01.539739Z","iopub.status.idle":"2025-04-05T05:30:01.550938Z","shell.execute_reply.started":"2025-04-05T05:30:01.539708Z","shell.execute_reply":"2025-04-05T05:30:01.549555Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"base_path = \"./ASVspoof2019_root/LA\"  # Base LA path\ntrain_dir = os.path.join(base_path, \"ASVspoof2019_LA_train\", \"flac\")  # .flac folder path\ntrain_label_file = os.path.join(base_path, \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.train.trn.txt\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:44:13.432628Z","iopub.execute_input":"2025-04-05T05:44:13.432996Z","iopub.status.idle":"2025-04-05T05:44:13.438633Z","shell.execute_reply.started":"2025-04-05T05:44:13.432967Z","shell.execute_reply":"2025-04-05T05:44:13.437265Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"ls ./ASVspoof2019_root/LA/ASVspoof2019_LA_train/flac | head\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:44:29.183873Z","iopub.execute_input":"2025-04-05T05:44:29.184295Z","iopub.status.idle":"2025-04-05T05:44:29.337722Z","shell.execute_reply.started":"2025-04-05T05:44:29.184258Z","shell.execute_reply":"2025-04-05T05:44:29.336191Z"}},"outputs":[{"name":"stdout","text":"ls: cannot access './ASVspoof2019_root/LA/ASVspoof2019_LA_train/flac': No such file or directory\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/flac\")[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:45:39.036520Z","iopub.execute_input":"2025-04-05T05:45:39.036990Z","iopub.status.idle":"2025-04-05T05:45:39.312825Z","shell.execute_reply.started":"2025-04-05T05:45:39.036952Z","shell.execute_reply":"2025-04-05T05:45:39.311494Z"}},"outputs":[{"name":"stdout","text":"['LA_T_9552332.flac', 'LA_T_2040122.flac', 'LA_T_5827423.flac', 'LA_T_8315701.flac', 'LA_T_2298291.flac']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchaudio\n\nclass ASVspoofDataset(Dataset):\n    def __init__(self, data_dir, label_file, sample_rate=16000):\n        self.data_dir = data_dir\n        self.sample_rate = sample_rate\n        self.files, self.labels = self.load_labels(label_file)\n\n    def load_labels(self, label_file):\n        files = []\n        labels = {}\n        with open(label_file, 'r') as f:\n            for line in f.readlines():\n                parts = line.strip().split()\n                filename = parts[1]  # e.g., LA_T_1000137\n                label = 1 if parts[-1] == 'spoof' else 0\n                files.append(filename)\n                labels[filename] = label\n        return files, labels\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        filename = self.files[idx]\n        label = self.labels[filename]\n        filepath = os.path.join(self.data_dir, filename + \".flac\")\n        \n        waveform, sr = torchaudio.load(filepath)\n        if sr != self.sample_rate:\n            waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.sample_rate)(waveform)\n        \n        return waveform, torch.tensor(label, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:49:43.269727Z","iopub.execute_input":"2025-04-05T05:49:43.270108Z","iopub.status.idle":"2025-04-05T05:49:43.278854Z","shell.execute_reply.started":"2025-04-05T05:49:43.270080Z","shell.execute_reply":"2025-04-05T05:49:43.277654Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class ASVspoofDataset(Dataset):\n    def __init__(self, data_dir, label_file, sample_rate=16000, fixed_length=64000):\n        self.data_dir = data_dir\n        self.sample_rate = sample_rate\n        self.fixed_length = fixed_length\n        self.files, self.labels = self.load_labels(label_file)\n\n    def load_labels(self, label_file):\n        files = []\n        labels = {}\n        with open(label_file, 'r') as f:\n            for line in f.readlines():\n                parts = line.strip().split()\n                filename = parts[1]\n                label = 1 if parts[-1] == 'spoof' else 0\n                files.append(filename)\n                labels[filename] = label\n        return files, labels\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        filename = self.files[idx]\n        label = self.labels[filename]\n        filepath = os.path.join(self.data_dir, filename + \".flac\")\n\n        waveform, sr = torchaudio.load(filepath)\n        if sr != self.sample_rate:\n            waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.sample_rate)(waveform)\n\n        # Pad or trim to fixed length\n        if waveform.shape[1] < self.fixed_length:\n            padding = self.fixed_length - waveform.shape[1]\n            waveform = torch.nn.functional.pad(waveform, (0, padding))\n        else:\n            waveform = waveform[:, :self.fixed_length]\n\n        return waveform, torch.tensor(label, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:54:22.613278Z","iopub.execute_input":"2025-04-05T05:54:22.613748Z","iopub.status.idle":"2025-04-05T05:54:22.625772Z","shell.execute_reply.started":"2025-04-05T05:54:22.613718Z","shell.execute_reply":"2025-04-05T05:54:22.624524Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Updated base path and label file path based on your structure\ntrain_dir = \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/flac\"\ntrain_label_file = \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\"\n\n# Load dataset\ntrain_dataset = ASVspoofDataset(data_dir=train_dir, label_file=train_label_file)\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # smaller batch size for Kaggle GPU\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:54:25.968879Z","iopub.execute_input":"2025-04-05T05:54:25.969285Z","iopub.status.idle":"2025-04-05T05:54:26.007249Z","shell.execute_reply.started":"2025-04-05T05:54:25.969255Z","shell.execute_reply":"2025-04-05T05:54:26.006069Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class ResBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n        super(ResBlock, self).__init__()\n        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2)\n        self.bn1 = nn.BatchNorm1d(out_channels)\n        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding=kernel_size//2)\n        self.bn2 = nn.BatchNorm1d(out_channels)\n\n        # Shortcut layer to match dimensions\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv1d(in_channels, out_channels, kernel_size=1),\n                nn.BatchNorm1d(out_channels)\n            )\n\n    def forward(self, x):\n        residual = self.shortcut(x)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.bn2(self.conv2(x))\n        x += residual\n        return F.relu(x)\n\n\nclass RawNet2ResNet(nn.Module):\n    def __init__(self, input_dim=16000, num_classes=2):\n        super(RawNet2ResNet, self).__init__()\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm1d(32)\n        self.resblock1 = ResBlock(32, 64)\n        self.resblock2 = ResBlock(64, 64)\n        \n        # Corrected input_size for GRU\n        self.gru = nn.GRU(64, 64, batch_first=True)\n        self.fc = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.resblock1(x)\n        x = self.resblock2(x)\n        x, _ = self.gru(x.permute(0, 2, 1))  # shape: (batch, seq_len, features)\n        x = self.fc(x[:, -1, :])             # use last GRU output\n        return x\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:59:23.986718Z","iopub.execute_input":"2025-04-05T05:59:23.987159Z","iopub.status.idle":"2025-04-05T05:59:23.998377Z","shell.execute_reply.started":"2025-04-05T05:59:23.987131Z","shell.execute_reply":"2025-04-05T05:59:23.997271Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = RawNet2ResNet().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ndef train_model(model, train_loader, criterion, optimizer, epochs=5):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for waveforms, labels in tqdm(train_loader):\n            waveforms, labels = waveforms.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(waveforms)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:59:28.106117Z","iopub.execute_input":"2025-04-05T05:59:28.106579Z","iopub.status.idle":"2025-04-05T05:59:28.120330Z","shell.execute_reply.started":"2025-04-05T05:59:28.106546Z","shell.execute_reply":"2025-04-05T05:59:28.119275Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train_model(model, train_loader, criterion, optimizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T05:59:31.755596Z","iopub.execute_input":"2025-04-05T05:59:31.755985Z"}},"outputs":[{"name":"stderr","text":"  6%|▋         | 206/3173 [2:10:34<31:52:58, 38.69s/it]","output_type":"stream"}],"execution_count":null}]}